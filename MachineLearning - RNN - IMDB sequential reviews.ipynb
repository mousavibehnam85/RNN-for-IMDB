{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4252dce-8dd7-4e16-ab40-bcf6290d40af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-12 18:26:13.900420: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# RNNs are a type of neural network architecture designed for processing sequential data. They have loops or connections that allow \n",
    "# information to be passed from one step of the sequence to the next. This architecture is suitable for tasks where the order or context of\n",
    "# the input data is important, such as natural language processing, time series analysis, and speech recognition.\n",
    " ## RNN Neural Network\n",
    " # IMDB sequential data analysis\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f7e6c4c-6c8d-4ed4-abda-7f0de4301dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "25000 train sequences\n",
      "25000 test sequences\n",
      "Pad sequences (samples x time)\n",
      "input_train shape: (25000, 400)\n",
      "input_test shape: (25000, 400)\n"
     ]
    }
   ],
   "source": [
    "##You set max_features = 10000 to limit the vocabulary to the top 10,000 most common words.\n",
    "##Later, you set maxlen = 400 to ensure that each sequence (review) has a maximum length of 500 words by padding or truncating as needed.\n",
    "\n",
    "max_features = 10000  # Consider the top 10,000 most common words\n",
    "maxlen = 400  # Limit each review to 500 words\n",
    "batch_size = 32\n",
    "\n",
    "print('Loading data...')\n",
    "(input_train, y_train), (input_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(input_train), 'train sequences')\n",
    "print(len(input_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "input_train = sequence.pad_sequences(input_train, maxlen=maxlen) # You pad the sequences to make sure they all have the same length\n",
    "input_test = sequence.pad_sequences(input_test, maxlen=maxlen)\n",
    "print('input_train shape:', input_train.shape)\n",
    "print('input_test shape:', input_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9226fc80-a791-452a-acaa-01862b77f552",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32)) #This layer is responsible for learning the dense representations of words - \n",
    "# -or tokens in the dataset and 32 is the dimensionality of the embeddings.\n",
    "\n",
    "model.add(SimpleRNN(16))  #layer adds a Simple Recurrent Neural Network (RNN) layer with 32 units. This layer \n",
    "#processes sequences of input data and maintains a state while iterating through the sequence.\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))  #adds a fully connected layer to the neural network. In a dense layer,\n",
    "# each neuron/node in the current layer is connected to every neuron/node in the previous layer.\n",
    "# sigmoid function squashes the output of each neuron to a value between 0 and 1\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "##'rmsprop'. The optimizer is a method used to update the weights of the neural network during training.\n",
    "\n",
    "#'Binary_crossentropy' is a suitable loss function for binary classification problems. It measures the difference between \n",
    "# - predicted and actual values for binary outcomes, like predicting positive or negative sentiments.\n",
    "\n",
    "## The model will track accuracy ('acc') as the performance metric during training. Accuracy measures \n",
    "## - the percentage of correctly predicted samples compared to the total number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f7676a3-be83-441d-a932-08b127bd5078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch 1/5\n",
      "704/704 [==============================] - 44s 61ms/step - loss: 0.5683 - acc: 0.6828 - val_loss: 0.4169 - val_acc: 0.8216\n",
      "Epoch 2/5\n",
      "704/704 [==============================] - 43s 61ms/step - loss: 0.3351 - acc: 0.8620 - val_loss: 0.3200 - val_acc: 0.8760\n",
      "Epoch 3/5\n",
      "704/704 [==============================] - 44s 63ms/step - loss: 0.2652 - acc: 0.8948 - val_loss: 0.3483 - val_acc: 0.8460\n",
      "Epoch 4/5\n",
      "704/704 [==============================] - 45s 63ms/step - loss: 0.2298 - acc: 0.9130 - val_loss: 0.3657 - val_acc: 0.8344\n",
      "Epoch 5/5\n",
      "704/704 [==============================] - 44s 63ms/step - loss: 0.2042 - acc: 0.9250 - val_loss: 0.3122 - val_acc: 0.8780\n"
     ]
    }
   ],
   "source": [
    "print('Training...')\n",
    "history = model.fit(input_train, y_train, epochs=5, batch_size=batch_size, validation_split=0.1)\n",
    "#batch_size defines the number of samples (data points or instances) that will be propagated through the \n",
    "# - neural network at a time during each training iteration/epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21761949-71c1-4cf5-b0aa-dc4bcabe13de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 10s 13ms/step - loss: 0.3207 - acc: 0.8757\n",
      "Test accuracy: 87.57%\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(input_test, y_test)\n",
    "print(f'Test accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "## reducing RNN from 32 to 16 increased the accuracy and reduced the computation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80390690-c9d6-46d2-99ee-69f571dd2691",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
